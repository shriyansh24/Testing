\documentclass[12pt,a4paper]{article}
\usepackage[left=0.75cm,right=0.75cm,top=1cm,bottom=1cm]{geometry}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{fontawesome}
\usepackage{array}
\usepackage{times}

% Adjusted section and subsection spacing
\titleformat{\section}{\normalsize\bfseries}{\thesection}{1em}{}[\titlerule]
\titlespacing*{\section}{0pt}{*0.25}{*0.25} 
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}
\titlespacing*{\subsection}{0pt}{*0.25}{*0.1}

\setlength{\parindent}{0pt}
\setlength{\parskip}{0.3em}
\pagestyle{empty}

% Modified commands to remove extra white space
\newcommand{\cvitem}[4]{
  \textbf{#1} \hfill #2\\
  #3 \hfill #4 \par\vspace{-0.5em}
}

\newcommand{\workexp}[4]{
  \textbf{#1} \hfill #2\\
  #3 \hfill #4\\
  \vspace{-1em}
}

\begin{document}

\begin{center}
\textbf{\LARGE SHRIYANSH SINGH}\\
\normalsize
+1 930 333 5141 \,|\, shriyansh.singh24@gmail.com \,|\, \href{https://www.linkedin.com/in/shriyansh-bir-singh}{LinkedIn} \,|\, \href{https://github.com/shriyansh24}{GitHub}
\end{center}

\section*{EDUCATION}
\cvitem{Indiana University Bloomington}{Aug 2023 – May 2025}{Master of Science in Data Science}{Indiana, IN}\\[0.5em]
\textnormal{\textbf{Relevant Courses:} Applied Machine Learning, Data Mining, Intelligent Systems, Cloud Computing, Big Data Applications, Graph Analytics, and more.}

\section*{PROFESSIONAL EXPERIENCE}
\workexp{Machine Learning Intern}{April 2024 - Present}{Hyphenova AI, Los Angeles, CA}{
  \begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
    \item Led the end-to-end design, development, and deployment of NLP-based content filtering algorithms using Agile methodologies, driving a 30\% increase in brand-creator matches and a 15\% improvement in user satisfaction.
    \item Collaborated with cross-functional teams to develop advanced Random Forest models with enhanced feature selection, resulting in a 25\% boost in campaign performance.
    \item Deployed scalable ML models on AWS SageMaker; integrated real-time analytics that reduced data processing time by 40\% and supported production-level monitoring.
    \item Applied techniques such as SMOTE for data imbalance and model quantization for inference optimization, contributing to a 15\% accuracy improvement and faster deployment cycles.
    \item Streamlined data pipelines using Apache Spark and AWS to reduce latency and support a 3x increase in throughput for high-velocity data streams.
    \item Implemented continuous model monitoring and automated retraining pipelines to adapt to evolving data patterns while adhering to responsible AI practices.
  \end{itemize}
}

\workexp{Machine Learning Intern}{May 2022 - Oct 2022}{Enterprise Business Technologies Pvt Ltd, Mumbai, India}{
  \begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
    \item Developed a customer segmentation model using unsupervised techniques (K-means clustering, PCA), enhancing targeted marketing strategies and driving a 20\% increase in customer engagement.
    \item Optimized a predictive analytics pipeline by integrating XGBoost, resulting in a 15\% increase in forecasting precision.
    \item Collaborated with data engineering teams to design and deploy end-to-end ML solutions on Azure ML, reducing model deployment time by 30\% and accelerating feature roll-outs.
    \item Automated data preprocessing workflows with Python and Pandas, cutting manual effort by 50\% and expediting model training.
    \item Utilized time series forecasting to analyze customer behavior, supporting data-driven strategies that increased revenue by 10\%.
  \end{itemize}
}

\section*{PROJECTS}
\subsection*{Fraud Detection Using Graph Neural Networks}
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
  \item Developed a GraphSAGE-based GNN model to analyze complex entity relationships, achieving a 35\% increase in fraud detection accuracy.
  \item Engineered graph-based features using NetworkX and Neo4j, enhancing the model’s anomaly detection capabilities.
  \item Deployed the model on GCP for scalable, real-time fraud detection over high-dimensional data.
  \item Optimized training with distributed computing, reducing model training time by 40\%.
\end{itemize}

\subsection*{Document Summarization and Keyword Extraction}
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
  \item Implemented a BERT-based extractive summarization system using Hugging Face Transformers, improving document retrieval efficiency by 50\%.
  \item Developed a keyword extraction pipeline with SpaCy and NLTK, achieving 85\% precision in identifying key phrases.
  \item Integrated the system with Elasticsearch for scalable search and deployed via TensorFlow Serving for real-time performance.
  \item Fine-tuned models to optimize summarization accuracy by 30\% for domain-specific documents.
\end{itemize}

\subsection*{Object Detection and Classification in Satellite Images}
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
  \item Developed an object detection model using YOLOv5 to achieve 95\% accuracy in classifying satellite imagery.
  \item Enhanced detection in low-resolution images by 20\% through OpenCV-based preprocessing.
  \item Deployed on AWS SageMaker to handle terabytes of data in real time, facilitating rapid geospatial analysis.
  \item Optimized inference pipelines for parallel processing on the cloud, reducing latency by 35\%.
\end{itemize}

\subsection*{Image Classification for Autonomous Vehicles}
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
  \item Designed an image classification model using YOLOv3, achieving 98\% accuracy in identifying pedestrians, vehicles, and traffic signs.
  \item Reduced real-time inference latency by 25\% using TensorFlow Serving on Google AI Platform.
  \item Enhanced robustness through data augmentation, yielding a 15\% improvement in detection accuracy under diverse conditions.
  \item Implemented autoscaling and continuous model updates to handle fluctuating data loads from live video feeds.
\end{itemize}

\subsection*{NLP-Based Sentiment Analysis for Social Media}
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
  \item Developed a BERT-based sentiment analysis model that achieved 90\% accuracy in classifying social media posts.
  \item Fine-tuned the model with domain-specific datasets, improving sentiment prediction accuracy by 20\%.
  \item Deployed the solution as a RESTful API using FastAPI, supporting real-time analysis for large-scale social media monitoring.
  \item Scaled deployment with TensorFlow Serving to manage thousands of concurrent API requests.
\end{itemize}

\subsection*{Demand Forecasting for Retail}
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
  \item Designed and trained an LSTM-based model for demand forecasting, reducing forecast error by 25\%.
  \item Leveraged advanced time series preprocessing in Pandas to boost model accuracy.
  \item Deployed on Azure ML to harness cloud scalability for processing high-volume sales data.
  \item Automated model retraining pipelines to maintain forecast accuracy over time.
\end{itemize}

\subsection*{Predictive Maintenance in Manufacturing}
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
  \item Developed a predictive maintenance model using time series analysis and anomaly detection, cutting unexpected equipment failures by 40\%.
  \item Integrated IoT sensor data via Apache Kafka for real-time monitoring of equipment health.
  \item Deployed on AWS SageMaker to ensure scalable, reliable predictions across multiple manufacturing sites.
  \item Automated feature extraction and continuous learning to adapt to new data patterns.
\end{itemize}

\subsection*{Personalized Healthcare Recommendations}
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
  \item Designed a personalized recommendation engine using collaborative and content-based filtering, increasing patient treatment adherence by 30\%.
  \item Applied NLP techniques to extract insights from unstructured medical records for customized treatment plans.
  \item Deployed on Kubernetes for secure, scalable delivery of healthcare recommendations.
  \item Enhanced interpretability with SHAP values to support clinical decision-making.
\end{itemize}

\section*{SKILLS}
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
  \item \textbf{Programming Languages:} Python, C++, Java
  \item \textbf{Machine Learning Frameworks:} TensorFlow, PyTorch, Scikit-learn, XGBoost, Keras, Hugging Face Transformers
  \item \textbf{Data Processing:} Pandas, NumPy, Apache Spark, Dask, PySpark
  \item \textbf{Model Deployment:} TensorFlow Serving, TorchServe, AWS SageMaker, Google AI Platform, Azure ML, Docker, Kubernetes, FastAPI
  \item \textbf{Cloud Platforms:} AWS (S3, EC2, Lambda, SageMaker), GCP (AI Platform, BigQuery, Dataflow), Azure (ML, Synapse Analytics)
  \item \textbf{MLOps \& Infrastructure:} Terraform, Docker, Kubernetes, MLflow, Apache Airflow
  \item \textbf{Big Data Technologies:} Hadoop, Spark, Kafka, Apache Hive, Apache Flink
  \item \textbf{Data Storage:} MongoDB, Cassandra, Neo4j, SQL Databases, Data Lakes
  \item \textbf{AI Techniques:} NLP, Computer Vision, Deep Learning, Transfer Learning, Reinforcement Learning, Model Interpretability (SHAP, LIME)
  \item \textbf{DevOps for ML:} CI/CD Pipelines, Jenkins, GitLab CI, ML Pipelines (Kubeflow, TFX)
  \item \textbf{Additional:} Experience in model quantization, optimization, and responsible AI practices.
\end{itemize}

\end{document}
